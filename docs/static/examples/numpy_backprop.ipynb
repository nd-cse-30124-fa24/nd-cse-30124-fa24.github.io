{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.4713\n",
      "Epoch 2/50, Loss: 4.8140\n",
      "Epoch 3/50, Loss: 3.3925\n",
      "Epoch 4/50, Loss: 2.2720\n",
      "Epoch 5/50, Loss: 2.1561\n",
      "Epoch 6/50, Loss: 2.0228\n",
      "Epoch 7/50, Loss: 1.8311\n",
      "Epoch 8/50, Loss: 1.7122\n",
      "Epoch 9/50, Loss: 1.7189\n",
      "Epoch 10/50, Loss: 1.9309\n",
      "Epoch 11/50, Loss: 1.5439\n",
      "Epoch 12/50, Loss: 1.2936\n",
      "Epoch 13/50, Loss: 1.4601\n",
      "Epoch 14/50, Loss: 1.3112\n",
      "Epoch 15/50, Loss: 1.3715\n",
      "Epoch 16/50, Loss: 1.3340\n",
      "Epoch 17/50, Loss: 1.1482\n",
      "Epoch 18/50, Loss: 0.8838\n",
      "Epoch 19/50, Loss: 0.9438\n",
      "Epoch 20/50, Loss: 1.0354\n",
      "Epoch 21/50, Loss: 1.0274\n",
      "Epoch 22/50, Loss: 0.7570\n",
      "Epoch 23/50, Loss: 0.8099\n",
      "Epoch 24/50, Loss: 0.9842\n",
      "Epoch 25/50, Loss: 0.9360\n",
      "Epoch 26/50, Loss: 0.7909\n",
      "Epoch 27/50, Loss: 0.6327\n",
      "Epoch 28/50, Loss: 0.6026\n",
      "Epoch 29/50, Loss: 0.5921\n",
      "Epoch 30/50, Loss: 0.6213\n",
      "Epoch 31/50, Loss: 0.7523\n",
      "Epoch 32/50, Loss: 0.5985\n",
      "Epoch 33/50, Loss: 0.5793\n",
      "Epoch 34/50, Loss: 0.5092\n",
      "Epoch 35/50, Loss: 0.5471\n",
      "Epoch 36/50, Loss: 0.6018\n",
      "Epoch 37/50, Loss: 0.7500\n",
      "Epoch 38/50, Loss: 0.7046\n",
      "Epoch 39/50, Loss: 0.5480\n",
      "Epoch 40/50, Loss: 0.5019\n",
      "Epoch 41/50, Loss: 0.4417\n",
      "Epoch 42/50, Loss: 0.4171\n",
      "Epoch 43/50, Loss: 0.4197\n",
      "Epoch 44/50, Loss: 0.4143\n",
      "Epoch 45/50, Loss: 0.4516\n",
      "Epoch 46/50, Loss: 0.4651\n",
      "Epoch 47/50, Loss: 0.5471\n",
      "Epoch 48/50, Loss: 0.5236\n",
      "Epoch 49/50, Loss: 0.5036\n",
      "Epoch 50/50, Loss: 0.4147\n",
      "Test Accuracy: 89.34%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load MNIST data from sklearn's openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x = x / 255.0\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to integers and one-hot encode them\n",
    "y_train = y_train.astype(int).to_numpy()  # Convert to NumPy array\n",
    "y_test = y_test.astype(int).to_numpy()\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = one_hot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Neural network parameters\n",
    "input_size = 784       # 28x28 pixels flattened\n",
    "hidden_size = 64       # Number of neurons in the hidden layer\n",
    "output_size = 10       # Number of classes (digits 0-9)\n",
    "learning_rate = 0.01   # Learning rate\n",
    "epochs = 10            # Number of epochs\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)  # For reproducibility\n",
    "W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Loss function\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    return -np.mean(np.sum(targets * np.log(predictions + 1e-9), axis=1))\n",
    "\n",
    "# Forward pass\n",
    "def forward(X):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "# Backward pass\n",
    "def backward(X, y, z1, a1, z2, a2):\n",
    "    global W1, b1, W2, b2\n",
    "\n",
    "    # Output layer error\n",
    "    error_output = a2 - y\n",
    "    dW2 = np.dot(a1.T, error_output)\n",
    "    db2 = np.sum(error_output, axis=0, keepdims=True)\n",
    "\n",
    "    # Hidden layer error\n",
    "    error_hidden = np.dot(error_output, W2.T) * sigmoid_derivative(a1)\n",
    "    dW1 = np.dot(X.T, error_hidden)\n",
    "    db1 = np.sum(error_hidden, axis=0, keepdims=True)\n",
    "\n",
    "    # Update weights and biases\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    z1, a1, z2, a2 = forward(x_train)\n",
    "    loss = cross_entropy_loss(a2, y_train)\n",
    "    backward(x_train, y_train, z1, a1, z2, a2)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Testing accuracy\n",
    "_, _, _, a2_test = forward(x_test)\n",
    "predictions = np.argmax(a2_test, axis=1)\n",
    "accuracy = np.mean(predictions == np.argmax(y_test, axis=1))\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m y_test \u001b[38;5;241m=\u001b[39m one_hot_encoder\u001b[38;5;241m.\u001b[39mtransform(y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Convert data to PyTorch tensors\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     30\u001b[0m x_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the MNIST data\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x = x / 255.0\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to integers and one-hot encode them\n",
    "y_train = y_train.astype(int).to_numpy()\n",
    "y_test = y_test.astype(int).to_numpy()\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = one_hot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 784\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x_train_tensor)\n",
    "    loss = criterion(outputs, torch.argmax(y_train_tensor, dim=1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Testing accuracy\n",
    "with torch.no_grad():\n",
    "    outputs_test = model(x_test_tensor)\n",
    "    _, predicted = torch.max(outputs_test, 1)\n",
    "    accuracy = (predicted == torch.argmax(y_test_tensor, dim=1)).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the MNIST data\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "x = x / 255.0\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to integers and one-hot encode them\n",
    "y_train = y_train.astype(int).to_numpy()\n",
    "y_test = y_test.astype(int).to_numpy()\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = one_hot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot_encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Convert data to NumPy arrays before creating PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 784\n",
    "hidden_size = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(x_train_tensor)\n",
    "    loss = criterion(outputs, torch.argmax(y_train_tensor, dim=1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Testing accuracy\n",
    "with torch.no_grad():\n",
    "    outputs_test = model(x_test_tensor)\n",
    "    _, predicted = torch.max(outputs_test, 1)\n",
    "    accuracy = (predicted == torch.argmax(y_test_tensor, dim=1)).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy.item() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
